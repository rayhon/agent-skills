# Topics

<table>
  <tr>
    <td width="35%">
      <a href="https://www.youtube.com/watch?v=-ZL2MRAQSg0">
        <img src="https://img.youtube.com/vi/-ZL2MRAQSg0/maxresdefault.jpg" alt="Erik Bernhardsson - Serverless for AI at Scale" style="border-radius: 8px;">
      </a>
    </td>
    <td valign="top">
      <h3>Serverless for AI at Scale</h3>
      <p><strong>Erik Bernhardsson, CEO of Modal (Data Driven NYC)</strong></p>
      <ul>
        <li><strong>Beyond Kubernetes</strong>: Insight into why Modal built its own custom scheduler, file system, and container runtime from the ground up to achieve extreme efficiency for AI.</li>
        <li><strong>True Serverless GPU</strong>: A usage-based model where you pay strictly for active runtime, eliminating the "idle tax" common in traditional cloud GPU clusters.</li>
        <li><strong>Multi-Cloud Elasticity</strong>: How Modal pools GPU capacity across AWS, GCP, Oracle, and others to scale from zero to thousands of GPUs in seconds.</li>
        <li><strong>Infrastructure for GenAI</strong>: Use cases for high-scale image, audio (Suno), and video inference, as well as LLM fine-tuning and biotech applications.</li>
      </ul>
    </td>
  </tr>
</table>
